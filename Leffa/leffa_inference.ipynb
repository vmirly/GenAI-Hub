{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0b293e",
   "metadata": {},
   "source": [
    "LeFFA\n",
    "===\n",
    "\n",
    "**Learning Flow Fields in Attention for Controllable Person Image Generation**\n",
    "\n",
    " * Paper: https://arxiv.org/abs/2412.08486\n",
    "\n",
    "\n",
    "![Leffa Overview](../assets/leffa_overview.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270aea84",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/franciszzj/Leffa.git\n",
    "cd Leffa/\n",
    "\n",
    "\n",
    "conda create -n leffa python==3.10\n",
    "conda activate leffa\n",
    "pip install -r requirements.txt \n",
    "pip install ipykernel\n",
    "python -m ipykernel install --user --name leffa --display-name \"leffa\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897cfb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pyml/anaconda3/envs/leffa/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"Leffa_repo\")\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from leffa.transform import LeffaTransform\n",
    "from leffa.model import LeffaModel\n",
    "from leffa.inference import LeffaInference\n",
    "from leffa_utils.garment_agnostic_mask_predictor import AutoMasker\n",
    "from leffa_utils.densepose_predictor import DensePosePredictor\n",
    "from leffa_utils.utils import resize_and_center, list_dir, get_agnostic_mask_hd, get_agnostic_mask_dc, preprocess_garment_image\n",
    "from preprocess.humanparsing.run_parsing import Parsing\n",
    "from preprocess.openpose.run_openpose import OpenPose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17edde5",
   "metadata": {},
   "source": [
    "## Download checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9dc8e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 37 files: 100%|██████████| 37/37 [00:00<00:00, 3740.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/pyml/git_vmirly/GenAI-Hub/tmp/Leffa/ckpts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download checkpoints\n",
    "snapshot_download(repo_id=\"franciszzj/Leffa\", local_dir=\"./ckpts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a652e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from Leffa repo\n",
    "class LeffaPredictor(object):\n",
    "    def __init__(self):\n",
    "        self.mask_predictor = AutoMasker(\n",
    "            densepose_path=\"./ckpts/densepose\",\n",
    "            schp_path=\"./ckpts/schp\",\n",
    "        )\n",
    "\n",
    "        self.densepose_predictor = DensePosePredictor(\n",
    "            config_path=\"./ckpts/densepose/densepose_rcnn_R_50_FPN_s1x.yaml\",\n",
    "            weights_path=\"./ckpts/densepose/model_final_162be9.pkl\",\n",
    "        )\n",
    "\n",
    "        self.parsing = Parsing(\n",
    "            atr_path=\"./ckpts/humanparsing/parsing_atr.onnx\",\n",
    "            lip_path=\"./ckpts/humanparsing/parsing_lip.onnx\",\n",
    "        )\n",
    "\n",
    "        self.openpose = OpenPose(\n",
    "            body_model_path=\"./ckpts/openpose/body_pose_model.pth\",\n",
    "        )\n",
    "\n",
    "        vt_model_hd = LeffaModel(\n",
    "            pretrained_model_name_or_path=\"./ckpts/stable-diffusion-inpainting\",\n",
    "            pretrained_model=\"./ckpts/virtual_tryon.pth\",\n",
    "            dtype=\"float16\",\n",
    "        )\n",
    "        self.vt_inference_hd = LeffaInference(model=vt_model_hd)\n",
    "\n",
    "        vt_model_dc = LeffaModel(\n",
    "            pretrained_model_name_or_path=\"./ckpts/stable-diffusion-inpainting\",\n",
    "            pretrained_model=\"./ckpts/virtual_tryon_dc.pth\",\n",
    "            dtype=\"float16\",\n",
    "        )\n",
    "        self.vt_inference_dc = LeffaInference(model=vt_model_dc)\n",
    "\n",
    "        pt_model = LeffaModel(\n",
    "            pretrained_model_name_or_path=\"./ckpts/stable-diffusion-xl-1.0-inpainting-0.1\",\n",
    "            pretrained_model=\"./ckpts/pose_transfer.pth\",\n",
    "            dtype=\"float16\",\n",
    "        )\n",
    "        self.pt_inference = LeffaInference(model=pt_model)\n",
    "\n",
    "    def leffa_predict(\n",
    "        self,\n",
    "        src_image_path,\n",
    "        ref_image_path,\n",
    "        control_type,\n",
    "        ref_acceleration=False,\n",
    "        step=50,\n",
    "        scale=2.5,\n",
    "        seed=42,\n",
    "        vt_model_type=\"viton_hd\",\n",
    "        vt_garment_type=\"upper_body\",\n",
    "        vt_repaint=False,\n",
    "        preprocess_garment=False\n",
    "    ):\n",
    "        # Open and resize the source image.\n",
    "        src_image = Image.open(src_image_path)\n",
    "        src_image = resize_and_center(src_image, 768, 1024)\n",
    "\n",
    "        # For virtual try-on, optionally preprocess the garment (reference) image.\n",
    "        if control_type == \"virtual_tryon\" and preprocess_garment:\n",
    "            if isinstance(ref_image_path, str) and ref_image_path.lower().endswith('.png'):\n",
    "                # preprocess_garment_image returns a 768x1024 image.\n",
    "                ref_image = preprocess_garment_image(ref_image_path)\n",
    "            else:\n",
    "                raise ValueError(\"Reference garment image must be a PNG file when preprocessing is enabled.\")\n",
    "        else:\n",
    "            # Otherwise, load the reference image.\n",
    "            ref_image = Image.open(ref_image_path)\n",
    "            \n",
    "        ref_image = resize_and_center(ref_image, 768, 1024)\n",
    "\n",
    "        src_image_array = np.array(src_image)\n",
    "\n",
    "        if control_type == \"virtual_tryon\":\n",
    "            src_image = src_image.convert(\"RGB\")\n",
    "            model_parse, _ = self.parsing(src_image.resize((384, 512)))\n",
    "            keypoints = self.openpose(src_image.resize((384, 512)))\n",
    "            if vt_model_type == \"viton_hd\":\n",
    "                mask = get_agnostic_mask_hd(model_parse, keypoints, vt_garment_type)\n",
    "            elif vt_model_type == \"dress_code\":\n",
    "                mask = get_agnostic_mask_dc(model_parse, keypoints, vt_garment_type)\n",
    "            mask = mask.resize((768, 1024))\n",
    "        elif control_type == \"pose_transfer\":\n",
    "            mask = Image.fromarray(np.ones_like(src_image_array) * 255)\n",
    "\n",
    "        if control_type == \"virtual_tryon\":\n",
    "            if vt_model_type == \"viton_hd\":\n",
    "                src_image_seg_array = self.densepose_predictor.predict_seg(src_image_array)[:, :, ::-1]\n",
    "                src_image_seg = Image.fromarray(src_image_seg_array)\n",
    "                densepose = src_image_seg\n",
    "            elif vt_model_type == \"dress_code\":\n",
    "                src_image_iuv_array = self.densepose_predictor.predict_iuv(src_image_array)\n",
    "                src_image_seg_array = src_image_iuv_array[:, :, 0:1]\n",
    "                src_image_seg_array = np.concatenate([src_image_seg_array] * 3, axis=-1)\n",
    "                src_image_seg = Image.fromarray(src_image_seg_array)\n",
    "                densepose = src_image_seg\n",
    "        elif control_type == \"pose_transfer\":\n",
    "            src_image_iuv_array = self.densepose_predictor.predict_iuv(src_image_array)[:, :, ::-1]\n",
    "            src_image_iuv = Image.fromarray(src_image_iuv_array)\n",
    "            densepose = src_image_iuv\n",
    "\n",
    "        transform = LeffaTransform()\n",
    "        data = {\n",
    "            \"src_image\": [src_image],\n",
    "            \"ref_image\": [ref_image],\n",
    "            \"mask\": [mask],\n",
    "            \"densepose\": [densepose],\n",
    "        }\n",
    "        data = transform(data)\n",
    "        if control_type == \"virtual_tryon\":\n",
    "            if vt_model_type == \"viton_hd\":\n",
    "                inference = self.vt_inference_hd\n",
    "            elif vt_model_type == \"dress_code\":\n",
    "                inference = self.vt_inference_dc\n",
    "        elif control_type == \"pose_transfer\":\n",
    "            inference = self.pt_inference\n",
    "        output = inference(\n",
    "            data,\n",
    "            ref_acceleration=ref_acceleration,\n",
    "            num_inference_steps=step,\n",
    "            guidance_scale=scale,\n",
    "            seed=seed,\n",
    "            repaint=vt_repaint,\n",
    "        )\n",
    "        gen_image = output[\"generated_image\"][0]\n",
    "        return np.array(gen_image), np.array(mask), np.array(densepose)\n",
    "\n",
    "    def leffa_predict_vt(self, src_image_path, ref_image_path, ref_acceleration, step, scale, seed, vt_model_type, vt_garment_type, vt_repaint, preprocess_garment):\n",
    "        return self.leffa_predict(\n",
    "            src_image_path,\n",
    "            ref_image_path,\n",
    "            \"virtual_tryon\",\n",
    "            ref_acceleration,\n",
    "            step,\n",
    "            scale,\n",
    "            seed,\n",
    "            vt_model_type,\n",
    "            vt_garment_type,\n",
    "            vt_repaint,\n",
    "            preprocess_garment,  # Pass through the new flag.\n",
    "        )\n",
    "\n",
    "    def leffa_predict_pt(self, src_image_path, ref_image_path, ref_acceleration, step, scale, seed):\n",
    "        return self.leffa_predict(\n",
    "            src_image_path,\n",
    "            ref_image_path,\n",
    "            \"pose_transfer\",\n",
    "            ref_acceleration,\n",
    "            step,\n",
    "            scale,\n",
    "            seed,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ac3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leffa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
