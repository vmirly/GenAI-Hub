{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "885fb869",
   "metadata": {},
   "source": [
    "SAMRefiner\n",
    "=====\n",
    "\n",
    "**SAMRefiner: Taming Segment Anything Model for Universal Mask Refinement**\n",
    "\n",
    " * Paper: https://arxiv.org/abs/2502.06756\n",
    "\n",
    "![SAMRefiner Overview](../assets/samrefiner_overview.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9880d",
   "metadata": {},
   "source": [
    " * Installation\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/linyq2117/SAMRefiner.git SAMRefiner_repo\n",
    "\n",
    "# create conda env\n",
    "conda create -n SAMRefiner python=3.8 -y\n",
    "conda activate SAMRefiner\n",
    "\n",
    "# install packages\n",
    "pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "pip install opencv-python tqdm matplotlib scipy\n",
    "pip install FastGeodis --no-build-isolation --no-cache-dir\n",
    "\n",
    "cd SAMRefiner_repo/segment-anything; pip install -e .; cd ../../\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb446e",
   "metadata": {},
   "source": [
    "* Download model checkpoint\n",
    "\n",
    "```bash\n",
    "wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O SAMRefiner_repo/checkpoints\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f7d9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"SAMRefiner_repo\")\n",
    "from segment_anything import sam_model_registry\n",
    "from sam_refiner import sam_refiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c91aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"vit_h\"\n",
    "sam_checkpoint = \"SAMRefiner_repo/checkpoints/sam_vit_h_4b8939.pth\"\n",
    "device = \"cuda\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.eval().to(device=device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6629162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1137, 1068)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1068, 1137)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "image_path = \"../samples/plants.jpg\"\n",
    "mask_path = \"<path/to/init_mask>\"\n",
    "img = np.asarray(Image.open(image_path))\n",
    "if os.path.exists(mask_path):\n",
    "    init_masks = np.asarray(Image.open(mask_path), dtype=np.uint8)\n",
    "else:\n",
    "    init_masks = np.random.randint(0, 2, size=img.shape[:2], dtype=np.uint8)\n",
    "\n",
    "if np.max(init_masks) == 255:\n",
    "    init_masks = init_masks / 255\n",
    "\n",
    "refined_masks = sam_refiner(\n",
    "    image_path, [init_masks], sam\n",
    ")[0]\n",
    "                            \n",
    "print(refined_masks.shape)\n",
    "\n",
    "pred_mask = Image.fromarray(255*refined_masks[0].astype(np.uint8))\n",
    "pred_mask.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc212d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAMRefiner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
