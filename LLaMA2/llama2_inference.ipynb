{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2dc12e",
   "metadata": {},
   "source": [
    "LLaMA 2\n",
    "===\n",
    "\n",
    "**Llama 2: Open Foundation and Fine-Tuned Chat Models**\n",
    "\n",
    " * Paper: https://arxiv.org/abs/2307.09288\n",
    "\n",
    "![Llama 2 Overview](../assets/llama2_overview.png)\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/facebookresearch/llama/ llama_repo\n",
    "```\n",
    "\n",
    "Folder structure:\n",
    "```bash\n",
    "llama_repo/\n",
    "├── CODE_OF_CONDUCT.md\n",
    "├── CONTRIBUTING.md\n",
    "├── download.sh\n",
    "├── example_chat_completion.py\n",
    "├── example_text_completion.py\n",
    "├── LICENSE\n",
    "├── llama\n",
    "│   ├── generation.py\n",
    "│   ├── __init__.py\n",
    "│   ├── model.py\n",
    "│   └── tokenizer.py\n",
    "├── MODEL_CARD.md\n",
    "├── README.md\n",
    "├── requirements.txt\n",
    "├── Responsible-Use-Guide.pdf\n",
    "├── setup.py\n",
    "├── UPDATES.md\n",
    "└── USE_POLICY.md\n",
    "```\n",
    "\n",
    "* Insrallation\n",
    "```bash\n",
    "pip install torch\n",
    "cd llama_repo\n",
    "pip install -e .\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
