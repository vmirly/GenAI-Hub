{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2dc12e",
   "metadata": {},
   "source": [
    "LLaMA 2\n",
    "===\n",
    "\n",
    "**Llama 2: Open Foundation and Fine-Tuned Chat Models**\n",
    "\n",
    " * Paper: https://arxiv.org/abs/2307.09288\n",
    "\n",
    "![Llama 2 Overview](../assets/llama2_overview.png)\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/facebookresearch/llama/ llama_repo\n",
    "```\n",
    "\n",
    "Folder structure:\n",
    "```bash\n",
    "llama_repo/\n",
    "├── CODE_OF_CONDUCT.md\n",
    "├── CONTRIBUTING.md\n",
    "├── download.sh\n",
    "├── example_chat_completion.py\n",
    "├── example_text_completion.py\n",
    "├── LICENSE\n",
    "├── llama\n",
    "│   ├── generation.py\n",
    "│   ├── __init__.py\n",
    "│   ├── model.py\n",
    "│   └── tokenizer.py\n",
    "├── MODEL_CARD.md\n",
    "├── README.md\n",
    "├── requirements.txt\n",
    "├── Responsible-Use-Guide.pdf\n",
    "├── setup.py\n",
    "├── UPDATES.md\n",
    "└── USE_POLICY.md\n",
    "```\n",
    "\n",
    "* Insrallation\n",
    "```bash\n",
    "pip install torch\n",
    "cd llama_repo\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1febd4",
   "metadata": {},
   "source": [
    " * Getting the model\n",
    "\n",
    "# Feel out the request form at https://www.llama.com/llama-downloads/\n",
    "\n",
    "![Llama Request Form](../assets/llama_request_form.png)\n",
    "\n",
    "```bash\n",
    "pip install llama-stack -U\n",
    "\n",
    "llama model list --show-all\n",
    "\n",
    "llama download --source huggingface --model-id Llama-2-7b\n",
    "# Successfully downloaded model to /home/pyml/.llama/checkpoints/Llama-2-7b\n",
    "```\n",
    "\n",
    " * For more information, please visit https://github.com/meta-llama/llama-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d1d5dc",
   "metadata": {},
   "source": [
    "## Text Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5f256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fire\n",
    "\n",
    "from llama import Llama\n",
    "from typing import List\n",
    "\n",
    "#ValueError: Error initializing torch.distributed using env:// rendezvous: environment variable RANK expected, but not set\n",
    "# ValueError: Error initializing torch.distributed using env:// rendezvous: environment variable WORLD_SIZE expected, but not set\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "\n",
    "#ValueError: Error initializing torch.distributed using env:// rendezvous: environment variable MASTER_ADDR expected, but not set\n",
    "#ValueError: Error initializing torch.distributed using env:// rendezvous: environment variable MASTER_PORT expected, but not set\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1c0c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pyml/anaconda3/envs/llama/lib/python3.12/site-packages/torch/__init__.py:1240: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 6.28 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama.generation.Llama at 0x7fc53c4666c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ckpt dir: ~/.llama/checkpoints/Llama-2-7b/\n",
    "ckpt_dir = os.path.join(os.path.expanduser(\"~\"), \".llama\", \"checkpoints\", \"Llama-2-7b\")\n",
    "tokenizer_path = os.path.join(ckpt_dir, \"tokenizer.model\")\n",
    "max_seq_len = 128\n",
    "max_batch_size = 4\n",
    "max_gen_len = 64\n",
    "top_p = 0.95\n",
    "temperature = 0.6\n",
    "\n",
    "\n",
    "generator = Llama.build(\n",
    "    ckpt_dir=ckpt_dir,\n",
    "    tokenizer_path=tokenizer_path,\n",
    "    max_seq_len=max_seq_len,\n",
    "    max_batch_size=max_batch_size,\n",
    ")\n",
    "\n",
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6e9b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is \n",
      "> 1000 years old and is one of the most popular tourist destinations in the world. It is the most visited city in the world and it is famous for its museums, monuments, theaters, and historical buildings.\n",
      "The city is located on the River Seine, which divides it into two\n",
      "\n",
      "==================================\n",
      "\n",
      "The largest mammal in the world is \n",
      "> 10 meters (33 feet) long and weighs 150 tons (136 metric tons). This massive beast is the blue whale.\n",
      "The blue whale is the largest animal that ever lived. Scientists say it is the biggest animal ever to have existed on Earth.\n",
      "\n",
      "\n",
      "==================================\n",
      "\n",
      "The process of photosynthesis occurs in \n",
      "> 2 stages. The first stage is the light dependent stage. During the light dependent stage the light energy is converted into chemical energy. The second stage is the light independent stage. During the light independent stage the chemical energy is converted into ATP and NADPH.\n",
      "Photosynthesis is the process by which plants convert\n",
      "\n",
      "==================================\n",
      "\n",
      "The chemical symbol for gold is \n",
      "> 197. It is a precious metal that is used as a currency.\n",
      "Gold is one of the most precious metals in the world. It is used as a currency and has been used for thousands of years. Gold is also used in jewelry and other decorative items.\n",
      "\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"The capital of France is \",\n",
    "    \"The largest mammal in the world is \",\n",
    "    \"The process of photosynthesis occurs in \",\n",
    "    \"The chemical symbol for gold is \",\n",
    "]\n",
    "\n",
    "results = generator.text_completion(\n",
    "    prompts,\n",
    "    max_gen_len=max_gen_len,\n",
    "    temperature=temperature,\n",
    "    top_p=top_p,\n",
    ")\n",
    "\n",
    "for prompt, result in zip(prompts, results):\n",
    "    print(prompt)\n",
    "    print(f\"> {result['generation']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931e4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
