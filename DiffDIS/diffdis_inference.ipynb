{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d3651f",
   "metadata": {},
   "source": [
    "DiffDIS\n",
    "====\n",
    "\n",
    "**High-Precision Dichotomous Image Segmentation via Probing Diffusion Capacity**\n",
    "\n",
    " * Paper: https://arxiv.org/abs/2410.10105\n",
    "\n",
    "![DiffDIS Overview](../assets/diffdis_overview.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1c1782",
   "metadata": {},
   "source": [
    "\n",
    "! Installation\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/qianyu-dlut/DiffDIS.git\n",
    "cd DiffDIS\n",
    "\n",
    "pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "pip install -r requirements.txt\n",
    "pip install -e diffusers-0.30.2/\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    " * Download pre-trained model (sd-ultra)\n",
    "```python\n",
    "...: from huggingface_hub import snapshot_download\n",
    "...: \n",
    "...: # Replace this with your target directory\n",
    "...: local_dir = \"./models/sd-turbo\"\n",
    "...: \n",
    "...: # Download entire repository snapshot\n",
    "...: snapshot_download(\n",
    "...:     repo_id=\"stabilityai/sd-turbo\",\n",
    "...:     local_dir=local_dir,\n",
    "...:     local_dir_use_symlinks=False  # Set to False to copy files instead of symlinks\n",
    "...: )\n",
    "```\n",
    "\n",
    " * Download the checkpoint from [Google Drive](https://drive.google.com/drive/folders/1NKmUbn9BiV7xYy_1c2khIBAuOQNuYAdR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c15db",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install gdown\n",
    "\n",
    "# Right click on the file and get the link\n",
    "\n",
    "gdown https://drive.google.com/uc?id=FILE_ID\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13024b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "\n",
    "sys.path.append(\"DiffDIS-repo\")\n",
    "from core.diffdis_pipeline import DiffDISPipeline\n",
    "from diffusers import (\n",
    "    DDPMScheduler,\n",
    "    UNet2DConditionModel_diffdis,\n",
    "    AutoencoderKL,\n",
    ")\n",
    "\n",
    "from utils.seed_all import seed_all \n",
    "from utils.utils import check_mkdir\n",
    "from utils.config import diste1,diste2,diste3,diste4,disvd\n",
    "from utils.image_util import resize_res\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc6322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffdis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
