{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0042d2d4",
   "metadata": {},
   "source": [
    "SmolVLM\n",
    "=====\n",
    "**SmolVLM: Redefining small and efficient multimodal models**\n",
    "\n",
    " * Article: https://huggingface.co/blog/smolvlm\n",
    " * Paper: (SmolVLM) https://arxiv.org/pdf/2504.05299v1\n",
    " * Paper: (Idefics3) https://arxiv.org/pdf/2408.12637\n",
    "\n",
    "![SmolVLM / Idefics3 Architecture Overview](../assets/smolvlm_arch_overview.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f7f25",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install torch torchvision\n",
    "pip install transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af70a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-Instruct\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    #_attn_implementation=\"flash_attention_2\" if device == \"cuda\" else \"eager\"\n",
    ")\n",
    "\n",
    "model.eval().to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63fab17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1562]) torch.Size([1, 17, 3, 384, 384])\n"
     ]
    }
   ],
   "source": [
    "image_path = \"../samples/plants.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe the image?\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Prepare inputs\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "inputs = inputs.to(device)\n",
    "print(inputs[\"input_ids\"].shape, inputs[\"pixel_values\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "474f8842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:<image>Can you describe the image? Assistant: The image features two plants\n",
      "in golden-colored pots, placed on a wooden floor against a white wall. The\n",
      "plants are positioned in front of the wall, with the larger plant on the right\n",
      "side of the image and the smaller plant on the left side. Both plants have green\n",
      "leaves and appear to be healthy and well-maintained. The pots are cylindrical\n",
      "and made of metal, with a golden finish that contrasts with the natural green of\n",
      "the plants. The pots are placed on individual stands, which are also made of\n",
      "metal and have a spiral design, allowing the plants to be placed at different\n",
      "heights. The wooden floor is a light brown color, with a natural wood grain\n",
      "pattern, and it appears to be well-maintained. The white wall in the background\n",
      "provides a neutral backdrop for the plants and pots, making them the focal point\n",
      "of the image. The lighting in the image is soft and natural, with no harsh\n",
      "shadows, which helps to highlight the plants and their surroundings.\n"
     ]
    }
   ],
   "source": [
    "# Generate outputs\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "\n",
    "response = generated_texts[0]\n",
    "\n",
    "import textwrap\n",
    "print(textwrap.fill(response, width=80))  # Format the response for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd345ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "owlvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
